# 멋진 단어사전 만들기

## Node 15
- 들어가며
- 데이터 다운로드 및 분석
- 공백 기반 토큰화
- 형태소 기반 토큰화

<br>

## 단어사전 구축 순서
- KoNLPy(MeCab 클래스) 설치 & import
- 데이터 다운로드 및 분석
  - 라이브러리 import
  - 데이터 정보
  - 데이터 불러오기
  - 데이터 사용 기준에 따른 확인
  - 길이 1 문장 확인하기
  - 문장 수가 1,500을 초과하는 문장 길이 추출
  - 길이가 11인 문장 내용 확인
  - 중복 데이터 제거
  - 데이터 현황
  - 모든 데이터를 다 사용할 것인지?

<br>

- 1️⃣ Tenser를 이용한 Encoding
  - 공백 기반 토큰화
    - tokenize() 함수
    - 공백 기반 토큰화 실행 & 단어 사전 길이 확인
    - 단어 사전 확인
    - 공백 기반 토큰화 정리
    - 문제점
  - 형태소 기반 토큰화
    - MeCab 기반 단어사전 만들기
    - 형태소 기반 토큰화 진행 & 단어 사전 길이 확인
    - 형태소 기반 토큰화 정리
    - 인사이트
    - 더 좋은 성능을 내는 사례

<br>

- 생각해보기 - (1)
- 생각해보기 - (2)
- 생각해보기 - (3)

<br>

- 2️⃣ 모델이 생성한 Tenser ➡️ 문장으로 Decoding
  - mecab_tensor[100]을 원문으로 돌리기
    - tokenizer.sequences_to_texts() 함수
    - tokenizer.index_word 사용

<br>

- 회고
